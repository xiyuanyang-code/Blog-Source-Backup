---
title: Deep Learning Memo
date: 2025-03-10 19:22:02
index_img: /img/cover/dpexperience.png
excerpt: This blog records the writer's learning process of building and training neural networks by hand practically, including some tips, insights and memos.
math: true
categories:
  - Artificial Intelligence
  - Deep Learning
tags:
  - Convolutional Neural Networks
  - Artificial Intelligence
  - AlexNet
  - Image Clssification
  - Deep Learning
---

<style>
  html, body, .markdown-body {
    font-family: Georgia, sans, serif;
  }
</style>

# Deep Learning Memo

## Introduction

When traning a neural network, there is lot's of details that require attention, like how to set the learning rate, how to plot the fig, how to manage your project, etc. These details have no relations with the fundamental basis or the first principle of machine learning, they are just a sort of **words of experience**.

For green hands, there exists a huge gap between simply comprehending and copying other peoples neural networks from coding one's own neural network. It's a tough but effective process. Thus, I want to **record my road of practicing deep learning** by updating my Blog. This passage won't discuss the basic principle and only involve my own experiences and insights during my practical process.

If you want to update this blog with your own experiences, just contact with the author.

## 20250310 Using matplotlib in Linux

When using `matplotlib` in my WSL subsystem, I encountered errors as follows:

```bash
qt.qpa.plugin: Could not load the Qt platform plugin "xcb" in "" even though it was found.
This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.

Available platform plugins are: eglfs, minimal, minimalegl, offscreen, vnc, webgl, xcb.

[1]    5870 IOT instruction (core dumped)  python try_plotting.py
```

It seems that Linux cannot load the Qt platform plugin, which as a result failed to load the images.

### Solutions

We cannot let Linux to directly show the plotted figure in the terminal for its lack of GUI interface. But we can realize it by changing Matplotlib's backend: 

```python
import matplotlib as mpl
mpl.use('Agg')
#...
#...
import matplotlib.plt as plt
# forbid scientific notation
np.set_printoptions(suppress=True)


# Then showing the figure by saving the figures.

plt.savefig("save/img.png")

```

Of course, you can use juypter notebook instead. Remember! Use `plt.close()` if you want to save more than one image.

## 20250310 Arranging my file-structure

The contents below is generated by deepseek-v3.

### Simplified Project Structure
```plaintext
your_project/
│
├── data/                    # Raw and processed data
│   ├── raw/                 
│   └── processed/           
│
├── models/                  # Trained models
│   ├── checkpoints/         # Model checkpoints
│   └── final/               # Final models
│
├── outputs/                 # Training outputs
│   ├── logs/                # Logs (e.g., TensorBoard)
│   ├── images/              # Generated images
│   └── plots/               # Plots
│
├── scripts/                 # Scripts
│   ├── train.py             # Training script
│   └── utils.py             # Utility functions
│
└── README.md                # Project description
```

### Code to Auto-Create Directories
```python
import os
from datetime import datetime

# Base directory
base_dir = "your_project"

# Subdirectories
dirs = {
    "data": ["raw", "processed"],
    "models": ["checkpoints", "final"],
    "outputs": ["logs", "images", "plots"],
    "scripts": []
}

# Create directories
for parent_dir, sub_dirs in dirs.items():
    parent_path = os.path.join(base_dir, parent_dir)
    os.makedirs(parent_path, exist_ok=True)
    for sub_dir in sub_dirs:
        sub_path = os.path.join(parent_path, sub_dir)
        os.makedirs(sub_path, exist_ok=True)

# Timestamped output directory
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
output_dir = os.path.join(base_dir, "outputs", timestamp)
os.makedirs(output_dir, exist_ok=True)

print(f"Directories created. Output directory: {output_dir}")
```

### Usage in Training Script
```python
import os
import matplotlib.pyplot as plt

# Example output directory
output_dir = "your_project/outputs/20231025_123456"

# Save model checkpoint
model_checkpoint_path = os.path.join(output_dir, "model_checkpoint.pth")
# torch.save(model.state_dict(), model_checkpoint_path)  # PyTorch example

# Save training log
log_file_path = os.path.join(output_dir, "training_log.txt")
with open(log_file_path, "w") as f:
    f.write("Epoch 1, Loss: 0.123\n")

# Save generated image
image_path = os.path.join(output_dir, "training_plot.png")
plt.plot([1, 2, 3], [4, 5, 6])
plt.savefig(image_path)
plt.close()

print(f"Training outputs saved to: {output_dir}")
```

### Additional Tips
1. **Use a Config File**:
   ```python
   # config.py
   BASE_DIR = "your_project"
   DATA_DIR = os.path.join(BASE_DIR, "data")
   MODELS_DIR = os.path.join(BASE_DIR, "models")
   OUTPUTS_DIR = os.path.join(BASE_DIR, "outputs")
   ```

2. **Use Logging**:
   ```python
   import logging
   logging.basicConfig(filename=os.path.join(output_dir, "training.log"), level=logging.INFO)
   logging.info("Epoch 1, Loss: 0.123")
   ```

3. **Version Control**:
   Add to `.gitignore`:
   ```plaintext
   your_project/data/
   your_project/models/
   your_project/outputs/
   ```

## Slices in Torch

Pytorch的切片操作和C++等语法风格存在巨大的差异。

在C++中，假设`matrix`是一个二维数组，那么`matrix[i][j]`就会返回这个数组在$(i, j)$位置处的元素的值。（**从本质上讲就是对一个二级指针取两次引用**）

在Python中，`[]`为认为是**切片操作**，或者形式化地说就是**取原先数组的一个部分**，从实现上将就是实现**原数组的浅拷贝过程**。对于Torch的张量也是同样如此。并且Python中**切片**是可以叠加的，换句话说，在Python中`matrix[i][j]`在本质上是首先切片一个数组$i$行（**因为行是第一个维度**），接着这个数组就从$(m \times n)$的二维数组变成了$n$的一维数组，接下来第二次切片在原先切片的基础之上取$j$，等效地取出$A[i][j]$中的元素。

但是在很多时候这会产生误会！例如我希望取这个矩阵的**第一列**，很显然的想法是`matrix[:][0]`，但是很遗憾，这会取出**第一行**。因为切片操作是按顺序进行的，`matrix[:]`相当于返回这个原来的数组，nothing changes.

正确的做法：`matrix[:, 0]`

例如这个代码：

```python
def slice_indexing_practice(x: Tensor) -> Tuple[Tensor, Tensor, Tensor, Tensor]:
    """
    Given a two-dimensional tensor x, extract and return several subtensors to
    practice with slice indexing. Each tensor should be created using a single
    slice indexing operation.

    The input tensor should not be modified.

    Args:
        x: Tensor of shape (M, N) -- M rows, N columns with M >= 3 and N >= 5.

    Returns:
        A tuple of:
        - last_row: Tensor of shape (N,) giving the last row of x. It should be
          a one-dimensional tensor.
        - third_col: Tensor of shape (M, 1) giving the third column of x. It
          should be a two-dimensional tensor.
        - first_two_rows_three_cols: Tensor of shape (2, 3) giving the data in
          the first two rows and first three columns of x.
        - even_rows_odd_cols: Two-dimensional tensor containing the elements in
          the even-valued rows and odd-valued columns of x.
    """
    assert x.shape[0] >= 3
    assert x.shape[1] >= 5
    last_row = x[-1]
    third_col = x[:, 2]
    first_two_rows_three_cols = x[:2, :3]
    even_rows_odd_cols = x[::2, 1::2] 
    out = (
        last_row,
        third_col,
        first_two_rows_three_cols,
        even_rows_odd_cols,
    )
    return out 
```

> 节选自 [umich CV assignment 1](https://web.eecs.umich.edu/~justincj/teaching/eecs498/WI2022/assignment1.html)
